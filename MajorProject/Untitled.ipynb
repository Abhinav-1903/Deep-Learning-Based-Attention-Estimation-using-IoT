{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "701bae41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Abhinav Vannoj\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Found 7066 images belonging to 7 classes.\n",
      "WARNING:tensorflow:From C:\\Users\\Abhinav Vannoj\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Abhinav Vannoj\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Abhinav Vannoj\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Abhinav Vannoj\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Abhinav Vannoj\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "70/70 [==============================] - 35s 489ms/step - loss: 0.9420 - accuracy: 0.7261\n",
      "111/111 [==============================] - 54s 481ms/step\n",
      "Test Loss: 0.9420068860054016\n",
      "Test Accuracy: 0.7261160612106323\n",
      "Confusion Matrix:\n",
      "tf.Tensor(\n",
      "[[ 647   25   28   59  144   45   12]\n",
      " [  10   98    1    1    1    0    0]\n",
      " [ 149   16  423   45  148  148   89]\n",
      " [  31    3   18 1637   80   14   42]\n",
      " [  76    5   23  121  921   50   20]\n",
      " [ 133   20   68   85  301  523    9]\n",
      " [  19    3   36   29   33   10  667]], shape=(7, 7), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Set the path to the directory containing your test images\n",
    "test_dir = r'C:\\Users\\Abhinav Vannoj\\Downloads\\MajorProject-main\\MajorProject-main\\Data\\Emotion_dataset\\validation'\n",
    "\n",
    "# Set the image size based on your model's input size\n",
    "IMAGE_SIZE = (48, 48)\n",
    "\n",
    "# Create an ImageDataGenerator for test data\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create a test dataset\n",
    "test_dataset = test_datagen.flow_from_directory(\n",
    "    directory=test_dir,\n",
    "    target_size=IMAGE_SIZE,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False,  # Set to False to maintain the order of predictions\n",
    "    batch_size=64  # Adjust based on your system's memory\n",
    ")\n",
    "\n",
    "# Load the saved model\n",
    "with open(\"model.json\", \"r\") as json_file:\n",
    "    loaded_model_json = json_file.read()\n",
    "    model = tf.keras.models.model_from_json(loaded_model_json)\n",
    "\n",
    "# Load the model weights\n",
    "model.load_weights(\"model_final.h5\")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',  # Add your optimizer\n",
    "              loss='categorical_crossentropy',  # Add your loss function\n",
    "              metrics=['accuracy'])  # Add your metrics\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "# Evaluate the model on the test dataset\n",
    "test_evaluation = model.evaluate(test_dataset, steps=70)  # Adjust the number of steps as needed\n",
    "\n",
    "\n",
    "# Get predictions on the test dataset\n",
    "predictions = model.predict(test_dataset)\n",
    "\n",
    "# Convert predictions to class labels\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Get true labels\n",
    "true_labels = test_dataset.classes\n",
    "\n",
    "# Calculate confusion matrix\n",
    "confusion_matrix = tf.math.confusion_matrix(\n",
    "    true_labels,\n",
    "    predicted_classes,\n",
    "    num_classes=len(test_dataset.class_indices)\n",
    ")\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print(\"Test Loss:\", test_evaluation[0])\n",
    "print(\"Test Accuracy:\", test_evaluation[1])\n",
    "\n",
    "# Print or use the confusion matrix as needed\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0e5207",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
