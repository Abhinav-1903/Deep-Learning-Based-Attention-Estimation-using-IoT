{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95edbb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Abhinav Vannoj\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "opened camera\n",
      "gaze tracking object created\n",
      "WARNING:tensorflow:From C:\\Users\\Abhinav Vannoj\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\Abhinav Vannoj\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "excel sheet open now\n",
      "1/1 [==============================] - 1s 640ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "1/1 [==============================] - 0s 94ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n"
     ]
    }
   ],
   "source": [
    "#all imports \n",
    "from keras.models import load_model\n",
    "from keras.models import model_from_json\n",
    "from time import sleep\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing import image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from GazeTracking.gaze_tracking import GazeTracking\n",
    "import xlsxwriter     \n",
    "import time      \n",
    "\n",
    "#function to return the mapping for label to the values of the emotions\n",
    "def get_number(label):\n",
    "    if(label==0):\n",
    "        return 0.788\n",
    "    elif(label==1):\n",
    "        return 0.511\n",
    "    elif(label==2):\n",
    "        return 0.788\n",
    "    elif(label==3):\n",
    "        return 0.847\n",
    "    elif(label == 4):\n",
    "        return 0.7083\n",
    "    elif(label==5):\n",
    "        return 0.725\n",
    "    elif(label ==6):\n",
    "        return  1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "webcam = cv2.VideoCapture(0) #open the camera\n",
    "print(\"opened camera\")\n",
    "\n",
    "gaze = GazeTracking() #gaze tracking object\n",
    "print(\"gaze tracking object created\")\n",
    "# ... (previous code)\n",
    "\n",
    "cascade_classifier = cv2.CascadeClassifier(r\"C:\\Users\\Abhinav Vannoj\\Downloads\\SRIPRIYA CODE\\MajorProject\\project\\MajorProject\\EmotionRecognitionmodels\\frontalface.xml\")\n",
    "\n",
    "# Load the model architecture from JSON file\n",
    "json_file = open('model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(loaded_model_json)\n",
    "\n",
    "# Load the model weights\n",
    "model.load_weights(\"model_final.h5\")\n",
    "\n",
    "\n",
    "class_labels=['Angry','Disgust','Fear','Happy','Neutral','Sad','Surprise'] #classes of the emotions\n",
    "\n",
    "#create an excel sheet to write write data\n",
    "book = xlsxwriter.Workbook(r'C:\\Users\\Abhinav Vannoj\\Downloads\\SRIPRIYA CODE\\MajorProject\\project\\MajorProject\\Data\\sheets\\data.xlsx')     \n",
    "sheet = book.add_worksheet('data')\n",
    "print(\"excel sheet open now\")\n",
    "row = 0    \n",
    "column = 0   \n",
    "\n",
    "#Time information variables\n",
    "TT =240 #runs for TT frames , 1 minute = 120 frames\n",
    "sleep_time = 0.499 #sleeps for 0.499 ~ 0.5 secs, so runs at 2fps\n",
    "t=0\n",
    "\n",
    "i=0\n",
    "while (TT > 0):\n",
    "    _, frame = webcam.read()\n",
    "    labels = [] #labels initialized as an empty list \n",
    "\n",
    "    gray = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY) # gray scale the image\n",
    "    faces = cascade_classifier.detectMultiScale(gray,1.3,5) #detect the faces\n",
    "\n",
    "    #for each face detected in the image\n",
    "    for (x,y,w,h) in faces:\n",
    "\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,0,0),2) #put a rectagle on the face\n",
    "        roi_gray = gray[y:y+h,x:x+w] #cut out the face in gray\n",
    "        roi_gray = cv2.resize(roi_gray, (48, 48), fx=100, fy=100, interpolation=cv2.INTER_CUBIC)\n",
    "        roi_rgb = cv2.cvtColor(roi_gray, cv2.COLOR_GRAY2RGB)\n",
    "        crop = frame[y:y+h, x:x+w]  # save the face in color format\n",
    "\n",
    "        if np.sum([roi_gray]) != 0:  # if the face is present and the image is not all dark\n",
    "            # Emotion Detection part\n",
    "            roi = roi_rgb.astype('float') / 255.0\n",
    "            roi = img_to_array(roi)\n",
    "            roi = np.expand_dims(roi, axis=0)\n",
    "\n",
    "            preds = model.predict(roi)[0]  # do the prediction\n",
    "            label = class_labels[preds.argmax()]  # get the label\n",
    "            label_position = (x, y)  # make a tuple of the coordinates where the face begins\n",
    "            cv2.putText(frame, label, label_position, cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 255, 255), 3)  # print stuff on the frame\n",
    "\n",
    "            #Gaze Tracking part\n",
    "            gaze.refresh(frame) #give the source image to the gaze tracking object\n",
    "            frame = gaze.annotated_frame() #set the markings on the pupils\n",
    "            hr=gaze.horizontal_ratio()\n",
    "            vr=gaze.vertical_ratio()\n",
    "            label_position = (x-2,y-50)\n",
    "            label = get_number(label)\n",
    "            l=[]  \n",
    "            l.append(hr)\n",
    "            l.append(vr)\n",
    "            l.append(preds.argmax())\n",
    "            for x in l:\n",
    "                #print()\n",
    "                sheet.write(row, column, x)\n",
    "                column+=1\n",
    "            row += 1\n",
    "            column=0\n",
    "            cv2.imshow(\"Demo\", frame)\n",
    "            cv2.imwrite(r\"C:\\Users\\Abhinav Vannoj\\Downloads\\MajorProject-main\\MajorProject-main\\Data\\Images\\kang\"+str(i)+'.jpg',crop)\n",
    "            sheet.insert_image(row-1,3,r\"C:\\Users\\Abhinav Vannoj\\Downloads\\MajorProject-main\\MajorProject-main\\Data\\Images\\kang\"+str(i)+'.jpg')            \n",
    "            i+=1\n",
    "    if cv2.waitKey(1) == 27 or 0xFF == ord('q'):\n",
    "        break\n",
    "    time.sleep(sleep_time) #sleeps till the amount of time specified in 'sleep_time' variable\n",
    "    TT = TT -1 #reduce the number of frames captured\n",
    "book.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d659db7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d923a13d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
